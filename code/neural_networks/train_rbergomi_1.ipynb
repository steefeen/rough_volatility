{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the rough Bergomi model part 1\n",
    "\n",
    "In this notebook we train a neural network for the rough Bergomi model for expiries in the range [0,0.008].\n",
    "\n",
    "Be aware that the datasets are rather large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, split and scale the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PART = str(1)\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "wd = os.getcwd()\n",
    "\n",
    "path_seperator = os.path.sep\n",
    "\n",
    "# Load contract grid:\n",
    "logMoneyness = pd.read_csv(wd + path_seperator + 'data' + path_seperator + 'logMoneyness.txt', delimiter=\",\", header = None).values\n",
    "expiries = pd.read_csv(wd + path_seperator + 'data' + path_seperator + 'expiries.txt', delimiter=\",\", header = None).values\n",
    "\n",
    "# Set useful parameters:\n",
    "nIn = 7\n",
    "nOut = 175\n",
    "nXi = 4\n",
    "\n",
    "# Load training data:\n",
    "data_train = pd.read_csv(wd + path_seperator + 'data' + path_seperator + 'training_and_test_data' + path_seperator + 'rbergomi_training_data_' + MODEL_PART + '.csv', delimiter=\",\").values\n",
    "\n",
    "x_train = data_train[:,:nIn]\n",
    "y_train = data_train[:,nIn:nIn+nOut]\n",
    "data_train = None\n",
    "\n",
    "# Load test data:\n",
    "data_test = pd.read_csv(wd + path_seperator + 'data' + path_seperator + 'training_and_test_data' + path_seperator + 'rbergomi_test_data_' + MODEL_PART + '.csv', delimiter=\",\").values\n",
    "\n",
    "x_valid = data_test[:,:nIn]\n",
    "y_valid = data_test[:,nIn:nIn+nOut]\n",
    "data_test = None\n",
    "\n",
    "# Normalise data:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tmp1 = np.reshape(np.array([0.50,3.50,0.00]), (1, 3))\n",
    "tmp2 = np.reshape(np.array([0.00,0.75,-1.00]), (1, 3))\n",
    "ub = np.concatenate((tmp1,np.tile(1,(1,nXi))),1)\n",
    "lb = np.concatenate((tmp2,np.tile(0.0025,(1,nXi))),1)\n",
    "\n",
    "def myscale(x):\n",
    "    res=np.zeros(nIn)\n",
    "    for i in range(nIn):\n",
    "        res[i]=(x[i] - (ub[0,i] + lb[0,i])*0.5) * 2 / (ub[0,i] - lb[0,i])\n",
    "        \n",
    "    return res\n",
    "\n",
    "def myinverse(x):\n",
    "    res=np.zeros(nIn)\n",
    "    for i in range(nIn):\n",
    "        res[i]=x[i]*(ub[0,i] - lb[0,i]) *0.5 + (ub[0,i] + lb[0,i])*0.5\n",
    "        \n",
    "    return res\n",
    "\n",
    "# Scale inputs:\n",
    "x_train_mod = np.array([myscale(x) for x in x_train])\n",
    "x_valid_mod = np.array([myscale(x) for x in x_valid])\n",
    "\n",
    "# Scale and normalise output:\n",
    "scale_y =  StandardScaler()\n",
    "y_train_mod = scale_y.fit_transform(y_train)\n",
    "y_valid_mod = scale_y.transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/tensorflow1-15/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/tensorflow1-15/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/tensorflow1-15/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/tensorflow1-15/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/tensorflow1-15/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/tensorflow1-15/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "keras.backend.set_floatx('float64')\n",
    "\n",
    "def GetNetwork(nIn,nOut,nNodes,nLayers,actFun):\n",
    "    # Description: Creates a neural network of a specified structure\n",
    "    input1 = keras.layers.Input(shape=(nIn,))\n",
    "    layerTmp = keras.layers.Dense(nNodes,activation = actFun)(input1) \n",
    "    for i in range(nLayers-1):\n",
    "        layerTmp = keras.layers.Dense(nNodes,activation = actFun)(layerTmp) \n",
    "    output1 = keras.layers.Dense(nOut,activation = 'linear')(layerTmp)\n",
    "    return(keras.models.Model(inputs=input1, outputs=output1))\n",
    "\n",
    "def TrainNetwork(nn,batchsize,numEpochs,objFun,optimizer,xTrain,yTrain,xTest,yTest):\n",
    "    # Description: Trains a neural network and returns the network including the history\n",
    "    # of the training process.\n",
    "    nn.compile(loss = objFun, optimizer = optimizer)\n",
    "    history = nn.fit(xTrain, yTrain, batch_size = batchsize,\n",
    "                        validation_data = (xTest,yTest),\n",
    "                        epochs = numEpochs, verbose = True, shuffle=1) \n",
    "    return nn,history.history['loss'],history.history['val_loss']\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square( y_pred - y_true )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train neural network\n",
    "<span style=\"color:red\">This section can be skipped! Just go straight to \"Load network\" and load the already trained model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define model:\n",
    "model = GetNetwork(nIn,nOut,200,3,'elu')\n",
    "\n",
    "# Set seed\n",
    "import random\n",
    "random.seed(455165)\n",
    "\n",
    "# Train network\n",
    "model,loss1,vloss1 = TrainNetwork(model,32,5,root_mean_squared_error,keras.optimizers.Adam(),x_train_mod,y_train_mod,x_valid_mod,y_valid_mod)\n",
    "model,loss2,vloss2 = TrainNetwork(model,5000,2,root_mean_squared_error,keras.optimizers.Adam(),x_train_mod,y_train_mod,x_valid_mod,y_valid_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save network\n",
    "<span style=\"color:red\">This section can be skipped! Just go straight to \"Load network\" and load the already trained model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model:\n",
    "model.save(wd + path_seperator + 'data' + path_seperator + 'neural_network_weights' + path_seperator + 'rbergomi_model_' + MODEL_PART + '.h5')\n",
    "\n",
    "# Save weights (and scalings) in JSON format:\n",
    "# - You need to install 'json-tricks' first.\n",
    "# - We need this file for proper import into Matlab, R... etc.\n",
    "weights_and_more = model.get_weights()\n",
    "weights_and_more.append(0.5*(ub + lb))\n",
    "weights_and_more.append(np.power(0.5*(ub - lb),2))\n",
    "weights_and_more.append(scale_y.mean_)\n",
    "weights_and_more.append(scale_y.var_)\n",
    "\n",
    "import codecs, json \n",
    "for idx, val in enumerate(weights_and_more):\n",
    "    weights_and_more[idx] = weights_and_more[idx].tolist()\n",
    "\n",
    "json_str = json.dumps(weights_and_more)\n",
    "\n",
    "text_file = open(wd + path_seperator + 'data' + path_seperator + 'neural_network_weights' + path_seperator + 'rbergomi_weights_' + MODEL_PART + '.json', \"w\")\n",
    "text_file.write(json_str)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tensorflow1-15/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Load already trained neural network:\n",
    "model = keras.models.load_model(wd + path_seperator + 'data' + path_seperator + 'neural_network_weights' + path_seperator + 'rbergomi' + path_seperator + 'rbergomi_model_' + MODEL_PART + '.h5', \n",
    "                                custom_objects={'root_mean_squared_error': root_mean_squared_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters (H,eta,rho,xi1,xi2,...):  [ 0.10233071  2.46366781 -0.80421258  0.0711089   0.0868111   0.09131601\n",
      "  0.07464078]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1200 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify test sample to plot:\n",
    "sample_ind = 5006\n",
    "\n",
    "# Print parameters of test sample:\n",
    "print(\"Model Parameters (H,eta,rho,xi1,xi2,...): \",myinverse(x_valid_mod[sample_ind,:]))\n",
    "\n",
    "import scipy, matplotlib.pyplot as plt \n",
    "npts = 25\n",
    "x_sample = x_valid_mod[sample_ind,:]\n",
    "y_sample = y_valid_mod[sample_ind,:]\n",
    "\n",
    "prediction = scale_y.inverse_transform(model.predict(x_valid_mod))\n",
    "plt.figure(1,figsize=(14,12))\n",
    "j = -1\n",
    "for i in range(0,7):\n",
    "    j = j + 1\n",
    "    plt.subplot(4,4,j+1)\n",
    "    \n",
    "    plt.plot(logMoneyness[i*npts:(i+1)*npts],y_valid[sample_ind,i*npts:(i+1)*npts],'b',label=\"True\")\n",
    "    plt.plot(logMoneyness[i*npts:(i+1)*npts],prediction[sample_ind,i*npts:(i+1)*npts],'--r',label=\" Neural network\")\n",
    "\n",
    "    plt.title(\"Maturity=%1.3f \"%expiries[i*npts])\n",
    "    plt.xlabel(\"log-moneyness\")\n",
    "    plt.ylabel(\"Implied volatility\")\n",
    "    \n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prediction = scale_y.inverse_transform(model.predict(x_valid_mod))\n",
    "\n",
    "dl = {'prediction' + MODEL_PART: prediction.flatten(), 'y_valid' + MODEL_PART: y_valid.flatten()}\n",
    "df = pd.DataFrame(data=dl)\n",
    "\n",
    "df.to_csv(wd + path_seperator + 'data' + path_seperator + 'neural_network_weights' + path_seperator + 'rbergomi' + path_seperator + 'predictions' + path_seperator  + 'pred' + MODEL_PART + '.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136000, 175)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
